{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5889e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque robusto de importación y configuración de rutas\n",
    "import sys\n",
    "import os\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e4c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los tres datasets\n",
    "# Dataset 1\n",
    "ruta1 = '../data/dataset1_Medicaldataset.csv'\n",
    "df1 = pd.read_csv(ruta1)\n",
    "# Dataset 2\n",
    "ruta2 = '../data/dataset2_heart.csv'\n",
    "df2 = pd.read_csv(ruta2)\n",
    "# Dataset 3\n",
    "ruta3 = '../data/dataset3_heart_failure.csv'\n",
    "df3 = pd.read_csv(ruta3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9563127",
   "metadata": {},
   "source": [
    "# Preprocesamiento de los tres datasets\n",
    "\n",
    "Este notebook realiza la limpieza, transformación y selección de atributos para los tres datasets clínicos utilizados en la predicción de riesgo de infarto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b5a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño limpio Dataset 1: (39, 9)\n",
      "Tamaño limpio Dataset 2: (39, 14)\n",
      "Tamaño limpio Dataset 3: (39, 13)\n"
     ]
    }
   ],
   "source": [
    "# Limpieza de datos\n",
    "# Dataset 1\n",
    "clean1 = preprocessing.clean_data(df1)\n",
    "# Dataset 2\n",
    "clean2 = preprocessing.clean_data(df2)\n",
    "# Dataset 3\n",
    "clean3 = preprocessing.clean_data(df3)\n",
    "\n",
    "# Mostrar tamaños después de limpieza\n",
    "print('Tamaño limpio Dataset 1:', clean1.shape)\n",
    "print('Tamaño limpio Dataset 2:', clean2.shape)\n",
    "print('Tamaño limpio Dataset 3:', clean3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffa68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorización y log-transform según el artículo\n",
    "# Dataset 1: aplicar winsorización y log a Heart rate, CK-MB, Diastolic blood pressure, Blood sugar, Troponin\n",
    "cols1 = ['Heart rate', 'CK-MB', 'Diastolic blood pressure', 'Blood sugar', 'Troponin']\n",
    "wins1 = preprocessing.winsorize_columns(clean1, cols1)\n",
    "log1 = preprocessing.log_transform_columns(wins1, cols1)\n",
    "\n",
    "# Dataset 2: log-transform a trestbps y chol\n",
    "cols2 = ['trestbps', 'chol']\n",
    "log2 = preprocessing.log_transform_columns(clean2, cols2)\n",
    "\n",
    "# Dataset 3: log-transform a time, ejection_fraction, serum_creatinine, serum_sodium, age\n",
    "cols3 = ['time', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'age']\n",
    "log3 = preprocessing.log_transform_columns(clean3, cols3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff94c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributos seleccionados Dataset 1: Index(['Gender', 'Diastolic blood pressure', 'CK-MB', 'Troponin'], dtype='object')\n",
      "Atributos seleccionados Dataset 2: Index(['sex', 'trestbps', 'exang', 'oldpeak', 'slope'], dtype='object')\n",
      "Atributos seleccionados Dataset 3: Index(['age', 'platelets', 'sex', 'smoking', 'time'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Selección de atributos (ANOVA F-score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset 1\n",
    "X1 = log1.drop(columns=['Result'])\n",
    "y1 = (log1['Result'] == 'positive').astype(int)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X1_sel, features1 = preprocessing.select_features_anova(X1_train, y1_train, k=4)\n",
    "\n",
    "# Dataset 2\n",
    "X2 = log2.drop(columns=['target'])\n",
    "y2 = (log2['target'] > 0.5).astype(int)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "X2_sel, features2 = preprocessing.select_features_anova(X2_train, y2_train, k=5)\n",
    "\n",
    "# Dataset 3\n",
    "X3 = log3.drop(columns=['DEATH_EVENT'])\n",
    "y3 = log3['DEATH_EVENT']\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "X3_sel, features3 = preprocessing.select_features_anova(X3_train, y3_train, k=5)\n",
    "\n",
    "print('Atributos seleccionados Dataset 1:', features1)\n",
    "print('Atributos seleccionados Dataset 2:', features2)\n",
    "print('Atributos seleccionados Dataset 3:', features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ef3686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesamiento finalizado y datos guardados.\n"
     ]
    }
   ],
   "source": [
    "# Normalización\n",
    "X1_train_norm, X1_test_norm, scaler1 = preprocessing.normalize_data(X1_train[features1], X1_test[features1])\n",
    "X2_train_norm, X2_test_norm, scaler2 = preprocessing.normalize_data(X2_train[features2], X2_test[features2])\n",
    "X3_train_norm, X3_test_norm, scaler3 = preprocessing.normalize_data(X3_train[features3], X3_test[features3])\n",
    "\n",
    "# Guardar conjuntos procesados y scalers para siguientes etapas\n",
    "import joblib\n",
    "\n",
    "joblib.dump((X1_train_norm, y1_train, X1_test_norm, y1_test), '../data/dataset1_processed.joblib')\n",
    "joblib.dump((X2_train_norm, y2_train, X2_test_norm, y2_test), '../data/dataset2_processed.joblib')\n",
    "joblib.dump((X3_train_norm, y3_train, X3_test_norm, y3_test), '../data/dataset3_processed.joblib')\n",
    "joblib.dump((scaler1, scaler2, scaler3), '../data/scalers.joblib')\n",
    "\n",
    "print('Preprocesamiento finalizado y datos guardados.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
