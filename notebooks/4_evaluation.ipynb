{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b488e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta absoluta a src para cualquier modo de ejecución\n",
    "import sys\n",
    "src_path = r'C:\\Users\\rijar\\Proyectos\\Tesis\\estructura_final\\src'\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2bc19",
   "metadata": {},
   "source": [
    "# Importar librerías y funciones\n",
    "import sys, os\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "import joblib\n",
    "import evaluation\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos preprocesados\n",
    "X1_train, y1_train, X1_test, y1_test = joblib.load('../data/dataset1_processed.joblib')\n",
    "X2_train, y2_train, X2_test, y2_test = joblib.load('../data/dataset2_processed.joblib')\n",
    "X3_train, y3_train, X3_test, y3_test = joblib.load('../data/dataset3_processed.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3580b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos preprocesados\n",
    "import joblib\n",
    "X1_train, y1_train, X1_test, y1_test = joblib.load('../data/dataset1_processed.joblib')\n",
    "X2_train, y2_train, X2_test, y2_test = joblib.load('../data/dataset2_processed.joblib')\n",
    "X3_train, y3_train, X3_test, y3_test = joblib.load('../data/dataset3_processed.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee7cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando modelos para dataset1\n",
      "  LR: {'accuracy': 0.875, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666, 'auc': 1.0}\n",
      "  NB: {'accuracy': 0.875, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5714285714285714}\n",
      "  KNN: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "  SVM: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "  DT: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "  MLP: {'accuracy': 0.875, 'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666, 'auc': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rijar\\Proyectos\\Tesis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\rijar\\Proyectos\\Tesis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stacking_model: {'accuracy': 0.875, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 1.0}\n",
      "  voting_model: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'auc': 1.0}\n",
      "Evaluando modelos para dataset2\n",
      "  LR: {'accuracy': 0.5, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6666666666666667}\n",
      "  NB: {'accuracy': 0.5, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.6666666666666667}\n",
      "  KNN: {'accuracy': 0.5, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5}\n",
      "  SVM: {'accuracy': 0.375, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.4166666666666667}\n",
      "  DT: {'accuracy': 0.75, 'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'auc': 0.875}\n",
      "  MLP: {'accuracy': 0.75, 'precision': 0.5, 'recall': 0.5, 'f1': 0.5, 'auc': 0.7500000000000001}\n",
      "  stacking_model: {'accuracy': 0.625, 'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'auc': 0.5}\n",
      "  voting_model: {'accuracy': 0.625, 'precision': 0.3333333333333333, 'recall': 0.5, 'f1': 0.4, 'auc': 0.5}\n",
      "Evaluando modelos para dataset3\n",
      "  LR: {'accuracy': 0.875, 'precision': 0.875, 'recall': 1.0, 'f1': 0.9333333333333333, 'auc': 1.0}\n",
      "  NB: {'accuracy': 0.75, 'precision': 1.0, 'recall': 0.7142857142857143, 'f1': 0.8333333333333334, 'auc': 1.0}\n",
      "  KNN: {'accuracy': 0.875, 'precision': 0.875, 'recall': 1.0, 'f1': 0.9333333333333333, 'auc': 0.9285714285714286}\n",
      "  SVM: {'accuracy': 0.875, 'precision': 0.875, 'recall': 1.0, 'f1': 0.9333333333333333, 'auc': 0.5714285714285714}\n",
      "  DT: {'accuracy': 0.75, 'precision': 1.0, 'recall': 0.7142857142857143, 'f1': 0.8333333333333334, 'auc': 0.8571428571428572}\n",
      "  MLP: {'accuracy': 0.75, 'precision': 0.8571428571428571, 'recall': 0.8571428571428571, 'f1': 0.8571428571428571, 'auc': 0.7142857142857143}\n",
      "  stacking_model: {'accuracy': 0.875, 'precision': 0.875, 'recall': 1.0, 'f1': 0.9333333333333333, 'auc': 0.7142857142857143}\n",
      "  voting_model: {'accuracy': 0.75, 'precision': 0.8571428571428571, 'recall': 0.8571428571428571, 'f1': 0.8571428571428571, 'auc': 0.8571428571428571}\n",
      "Evaluación finalizada.\n"
     ]
    }
   ],
   "source": [
    "# Evaluar modelos individuales y ensemble\n",
    "import evaluation\n",
    "model_types = ['LR', 'NB', 'KNN', 'SVM', 'DT', 'MLP', 'stacking_model', 'voting_model']\n",
    "results = {}\n",
    "for ds_name, (X_test, y_test) in zip(\n",
    "    ['dataset1', 'dataset2', 'dataset3'],\n",
    "    [(X1_test, y1_test), (X2_test, y2_test), (X3_test, y3_test)]\n",
    "):\n",
    "    print(f'Evaluando modelos para {ds_name}')\n",
    "    ds_results = {}\n",
    "    for mtype in model_types:\n",
    "        try:\n",
    "            if mtype in ['stacking_model', 'voting_model']:\n",
    "                model = joblib.load(f'../data/{ds_name}_{mtype}.joblib')\n",
    "            else:\n",
    "                model = joblib.load(f'../data/{ds_name}_{mtype}_model.joblib')\n",
    "            metrics = evaluation.evaluate_model(model, X_test, y_test)\n",
    "            ds_results[mtype] = metrics\n",
    "            print(f'  {mtype}:', metrics)\n",
    "        except Exception as e:\n",
    "            print(f'  {mtype}: No disponible. Error: {e}')\n",
    "    results[ds_name] = ds_results\n",
    "\n",
    "print('Evaluación finalizada.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
